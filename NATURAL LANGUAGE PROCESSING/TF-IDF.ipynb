{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998cb72d",
   "metadata": {},
   "source": [
    "**Building TF-IDF from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2edb2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5937ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\reliance\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d485d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5845810b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eef436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate word2idx\n",
    "# Convert document into sequences of int , indeces\n",
    "idx = 0\n",
    "word2idx = {} # Keeping dictionary for word to idx mapping\n",
    "tokenized_docs = []\n",
    "\n",
    "for doc in df['text']:\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    doc_as_int = []\n",
    "    for token in tokens:\n",
    "        \n",
    "        if token not in word2idx:\n",
    "            word2idx[token] = idx\n",
    "            idx+=1\n",
    "            #saving the idx of each document\n",
    "            doc_as_int.append(word2idx[token])\n",
    "    # counting how many number of documents are coverted into number\n",
    "    tokenized_docs.append(doc_as_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bb460aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse mapping\n",
    "idx2word = {v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c3e0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another simple way to store words and can access it throgh index\n",
    "# This is more efficient than above dictionary\n",
    "vocabulary =[]\n",
    "for k in word2idx.keys():\n",
    "    vocabulary.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ebde9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of documents\n",
    "N = len(df[\"text\"])\n",
    "# Number of words\n",
    "V = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b07ec5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tf metrix\n",
    "tf = np.zeros((N,V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c00fbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate term frequency counts\n",
    "for i , doc_as_int in enumerate(tokenized_docs):\n",
    "    for j in doc_as_int:\n",
    "        tf[i,j] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25affeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c37d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
